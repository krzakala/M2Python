{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification with random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download the data. Mnist is so classic that it is already implemented in Keras. Let us see how data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "These are numbers corresponding to  5   0   4  and  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119f8c128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5kdETmLzIyIn/R+KxB3xQTzcVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169d8da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# and let us look at the numbers\n",
    "print(\"These are numbers corresponding to \",y_train[0],\" \",y_train[1],\" \",y_train[2],\" and \",y_train[3])\n",
    "plt.subplot(221)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to tranform these two dimensionnal images into a single dimensional vector, which we should also normalize between $0$ and $1$. We also wants to tranform the \"y\"s into one-hot-encoding type vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cateragories for these image is now encoded as : \n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.] \n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] \n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.] \n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32') #convert in float...\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  # .. and normalize\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"The cateragories for these image is now encoded as : \\n\",y_train[0][:],\"\\n\",y_train[1][:],\"\\n\",y_train[2][:],\"\\n\",y_train[3][:],\"\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is probably not easy to classify in direct space we shall not even try. Instead, we will try to go into a large dimensional space using random projection followed by a non linearity. Let us see how it works with $1000$ random projection followed by a function $\\rm{erf}$. First we create the random matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ! \r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=5000;\n",
    "from numpy import sqrt;\n",
    "from scipy.special import erf\n",
    "\n",
    "randmatrix=np.random.randn(num_features,784)/sqrt(784); # create a random matrix\n",
    "A=erf(np.transpose(np.dot(randmatrix,np.transpose(x_train))))# compute the projection\n",
    "print('Done ! \\r')\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to perform a linear regression in the space of $A$, which is a num_featuresx$60000$ matrix. if we perform a simple regression, we have a model where we want to predict label by $Y=A \\theta$. The  solution is obtained by writing \n",
    "$$\\theta=(A^T A)^{-1} A^T Y$$\n",
    "We thus create the correlation matrix $C=A^T A$ and the projection matrix $P=A^T Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CORRELATION=np.dot(np.transpose(A),A)\n",
    "PROJECTION=np.dot(np.transpose(A),y_train[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we compute the coefficient $\\theta$ by solving the linear system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COEFF,_,_,_=np.linalg.lstsq(CORRELATION,PROJECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done, we can try to make a prediction for the elements of the test set. First, we need again to perform the projection for these digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST=erf(np.dot(randmatrix,np.transpose(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we apply our linear prediction in features space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MULTI=np.dot(np.transpose(TEST),COEFF)\n",
    "MULTI.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the $10000$ digits, we now have a prediction saying how likely it belongs to the each of the $10$ classes. In order to choose the class, we gonna use the one that returns the largest elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of correct prediction is : 0.9674\n"
     ]
    }
   ],
   "source": [
    "PREDICTION=np.argmax(np.transpose(MULTI), axis=0)\n",
    "LABELTRUE=(np.dot(y_test,np.transpose([0,1,2,3,4,5,6,7,8,9])))\n",
    "print(\"Fraction of correct prediction is :\",sum(LABELTRUE==PREDICTION)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not bad for a such a simple and fact code. Beside, it is easy to go beyond to 98% with this approach by incerasing the number of projections, and playing with a regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
